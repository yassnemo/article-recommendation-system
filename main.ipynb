{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [45 lines of output]\n",
      "      Compiling surprise/similarities.pyx because it changed.\n",
      "      Compiling surprise/prediction_algorithms/matrix_factorization.pyx because it changed.\n",
      "      Compiling surprise/prediction_algorithms/optimize_baselines.pyx because it changed.\n",
      "      Compiling surprise/prediction_algorithms/slope_one.pyx because it changed.\n",
      "      Compiling surprise/prediction_algorithms/co_clustering.pyx because it changed.\n",
      "      [1/5] Cythonizing surprise/prediction_algorithms/co_clustering.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              self.avg_cltr_i = avg_cltr_i\n",
      "              self.avg_cocltr = avg_cocltr\n",
      "      \n",
      "              return self\n",
      "      \n",
      "          def compute_averages(self, np.ndarray[np.int_t] cltr_u,\n",
      "                                                   ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      surprise\\prediction_algorithms\\co_clustering.pyx:157:45: Invalid type.\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "          ~~~~^^\n",
      "        File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\pip-build-env-5kf9h4ol\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=[])\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\pip-build-env-5kf9h4ol\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 304, in _get_build_requires\n",
      "          self.run_setup()\n",
      "          ~~~~~~~~~~~~~~^^\n",
      "        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\pip-build-env-5kf9h4ol\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 320, in run_setup\n",
      "          exec(code, locals())\n",
      "          ~~~~^^^^^^^^^^^^^^^^\n",
      "        File \"<string>\", line 116, in <module>\n",
      "        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\pip-build-env-5kf9h4ol\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1154, in cythonize\n",
      "          cythonize_one(*args)\n",
      "          ~~~~~~~~~~~~~^^^^^^^\n",
      "        File \"C:\\Users\\HP\\AppData\\Local\\Temp\\pip-build-env-5kf9h4ol\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1321, in cythonize_one\n",
      "          raise CompileError(None, pyx_file)\n",
      "      Cython.Compiler.Errors.CompileError: surprise/prediction_algorithms/co_clustering.pyx\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.6.3)\n",
      "Collecting scikit-surprise\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install numpy pandas scikit-learn nltk scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization\n",
    "Convert article text into numerical vectors using TF-IDF vectorization from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "# If you already have the dataset, you can skip or comment this step\n",
    "!kaggle datasets download -d hsankesara/medium-articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['author', 'claps', 'reading_time', 'link', 'title', 'text']\n",
      "\n",
      "Sample data:\n",
      "             author claps  reading_time  \\\n",
      "0        Justin Lee  8.3K            11   \n",
      "1       Conor Dewey  1.4K             7   \n",
      "2  William Koehrsen  2.8K            11   \n",
      "3      Gant Laborde  1.3K             7   \n",
      "4  Emmanuel Ameisen   935            11   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
      "1  https://towardsdatascience.com/python-for-data...   \n",
      "2  https://towardsdatascience.com/automated-featu...   \n",
      "3  https://medium.freecodecamp.org/machine-learni...   \n",
      "4  https://blog.insightdatascience.com/reinforcem...   \n",
      "\n",
      "                                               title  \\\n",
      "0  Chatbots were the next big thing: what happene...   \n",
      "1  Python for Data Science: 8 Concepts You May Ha...   \n",
      "2  Automated Feature Engineering in Python – Towa...   \n",
      "3  Machine Learning: how to go from Zero to Hero ...   \n",
      "4  Reinforcement Learning from scratch – Insight ...   \n",
      "\n",
      "                                                text  \n",
      "0  Oh, how the headlines blared:\\nChatbots were T...  \n",
      "1  If you’ve ever found yourself looking up the s...  \n",
      "2  Machine learning is increasingly moving from h...  \n",
      "3  If your understanding of A.I. and Machine Lear...  \n",
      "4  Want to learn about applied Artificial Intelli...  \n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('articles.csv')\n",
    "\n",
    "# Display the first few rows and columns \n",
    "print(\"Available columns:\", df.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns used for recommendation: ['author', 'text', 'claps', 'title', 'reading_time', 'link']\n",
      "\n",
      "Cleaned data sample:\n",
      "             author                                               text claps  \\\n",
      "0        Justin Lee  Oh, how the headlines blared:\\nChatbots were T...  8.3K   \n",
      "1       Conor Dewey  If you’ve ever found yourself looking up the s...  1.4K   \n",
      "2  William Koehrsen  Machine learning is increasingly moving from h...  2.8K   \n",
      "3      Gant Laborde  If your understanding of A.I. and Machine Lear...  1.3K   \n",
      "4  Emmanuel Ameisen  Want to learn about applied Artificial Intelli...   935   \n",
      "\n",
      "                                               title  reading_time  \\\n",
      "0  Chatbots were the next big thing: what happene...            11   \n",
      "1  Python for Data Science: 8 Concepts You May Ha...             7   \n",
      "2  Automated Feature Engineering in Python – Towa...            11   \n",
      "3  Machine Learning: how to go from Zero to Hero ...             7   \n",
      "4  Reinforcement Learning from scratch – Insight ...            11   \n",
      "\n",
      "                                                link  \n",
      "0  https://medium.com/swlh/chatbots-were-the-next...  \n",
      "1  https://towardsdatascience.com/python-for-data...  \n",
      "2  https://towardsdatascience.com/automated-featu...  \n",
      "3  https://medium.freecodecamp.org/machine-learni...  \n",
      "4  https://blog.insightdatascience.com/reinforcem...  \n"
     ]
    }
   ],
   "source": [
    "# Clean Data Based on Available Columns\n",
    "\n",
    "# In case you use a different data set, you can replace the list below with the actual columns from your dataset\n",
    "# For example, if 'url' is missing, exclude it, etc.\n",
    "available_columns = ['title', 'text', 'claps', 'author', 'reading_time', 'link'] \n",
    "\n",
    "# Check if additional columns exist before selecting\n",
    "required_columns = ['author', 'text', 'claps', 'title', 'reading_time', 'link']\n",
    "existing_columns = [col for col in required_columns if col in df.columns]\n",
    "\n",
    "# Select only the existing columns\n",
    "df = df[existing_columns]\n",
    "\n",
    "# Display the cleaned dataFrame\n",
    "print(\"Columns used for recommendation:\", df.columns.tolist())\n",
    "print(\"\\nCleaned data sample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic-based recommendation function\n",
    "def get_recommendations(topic, n=2):\n",
    "    \n",
    "    # Match by tags\n",
    "    mask = df['tags'].str.contains(topic, case=False, na=False)\n",
    "    matches = df[mask].sort_values('claps', ascending=False)\n",
    "\n",
    "    if len(matches) >= n:\n",
    "        return matches.head(n)[['title', 'publication', 'reading_time', 'tags']]\n",
    "\n",
    "    # If not enough matches, use content similarity\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    text_matrix = tfidf.fit_transform(df['text'])\n",
    "    query_vec = tfidf.transform([topic])\n",
    "    similarities = cosine_similarity(query_vec, text_matrix)\n",
    "\n",
    "    top_indices = similarities[0].argsort()[-n:][::-1]\n",
    "    return df.iloc[top_indices][['title', 'publication', 'reading_time', 'tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive interface\n",
    "def interactive_recommendations():\n",
    "    topic = input(\"What topic interests you? \")\n",
    "    print(\"\\nFinding best articles about\", topic, \"...\")\n",
    "    recommendations = get_recommendations(topic)\n",
    "\n",
    "    print(\"\\nRecommended articles:\")\n",
    "    for idx, row in recommendations.iterrows():\n",
    "        print(f\"\\nTitle: {row['title']}\")\n",
    "        print(f\"Publication: {row['publication']}\")\n",
    "        print(f\"Reading time: {row['reading_time']} minutes\")\n",
    "        print(f\"Tags: {row['tags']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding best articles about data ...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tags'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 6: Run system\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43minteractive_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m, in \u001b[0;36minteractive_recommendations\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat topic interests you? \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinding best articles about\u001b[39m\u001b[38;5;124m\"\u001b[39m, topic, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mget_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRecommended articles:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m recommendations\u001b[38;5;241m.\u001b[39miterrows():\n",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m, in \u001b[0;36mget_recommendations\u001b[1;34m(topic, n)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(topic, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Match by tags\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(topic, case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     matches \u001b[38;5;241m=\u001b[39m df[mask]\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclaps\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(matches) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tags'"
     ]
    }
   ],
   "source": [
    "#  Run system\n",
    "interactive_recommendations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
